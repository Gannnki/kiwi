\documentclass{article}
\usepackage[utf8]{inputenc}


\begin{document}
Some definition in correspondence with ,,State'' that can help students better understand practical problems from a theoretical perspective.\\
\\
\noindent
1. State completeness\\
A state $x_{t}$ will be called complete if it is the best predictor of the future.A complete state includes not just all aspects of the environment that may have an impact on the future, but also the robot itself, the content ofits computer memory, the brain dumps of surrounding people, etc. Those are hard to obtain.\\
The future may be stochastic, but no variables prior to $x_{t}$  may influence the stochastic evolution of future states, unless this dependence is mediated through the state $x_{t}$.
\\
Thrun, Sebastian. "Probabilistic robotics." Communications of the ACM 45.3 (2002): 52-57.\\
\\
2. Markov Chain\\
A Markov chain is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.A Markov process is a stochastic process that satisfies the Markov property(sometimes characterized as "memorylessness").\\
\\
Gagniuc, Paul A. (2017). Markov Chains: From Theory to Implementation and Experimentation. USA, NJ: John Wiley & Sons. pp. 1â€“235. ISBN 978-1-119-38755-8.
\end{document}
